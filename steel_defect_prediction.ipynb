{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "!pip install ../input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/ > /dev/null\n",
    "package_path = '../input/unetmodelscript'\n",
    "import sys\n",
    "sys.path.append(package_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd '../input/attunetpytorch/EfficientUnet_pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientunet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd \"../../../working\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd \"../input/attentionsmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd \"../../working\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchvision.transforms import ToTensor,Compose,Normalize\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torchvision\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    '''Dataset for test prediction'''\n",
    "    def __init__(self, root, df, mean, std,i):\n",
    "        self.root = root\n",
    "        df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "        self.fnames = df['ImageId'].unique().tolist()\n",
    "        self.num_samples = len(self.fnames)\n",
    "        if(i==1):\n",
    "            \n",
    "            \n",
    "            self.transform = Compose([ToTensor(),Normalize(mean=mean, std=std)])\n",
    "                \n",
    "        if(i==2):\n",
    "            self.transform = Compose([HorizontalFlip(p=1),Normalize(mean=mean, std=std, p=1),ToTensor()])\n",
    "\n",
    "        if(i==3):\n",
    "             self.transform = Compose([VerticalFlip(p=1),Normalize(mean=mean, std=std, p=1),ToTensor()])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "        path = os.path.join(self.root, fname)\n",
    "        \n",
    "        image = cv2.imread(path)\n",
    "        images = self.transform(image)\n",
    "        return fname, images\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(probability,threshold , min_size):\n",
    "    '''Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored'''\n",
    "    \n",
    "    num_component, component = cv2.connectedComponents(probability.astype(np.uint8))\n",
    "    \n",
    "    predictions = np.zeros((256, 1600), np.float32)\n",
    "\n",
    "    num = 0\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        \n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "            num += 1\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_path = '../input/severstal-steel-defect-detection/sample_submission.csv'\n",
    "test_data_folder = \"../input/severstal-steel-defect-detection/test_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold = 0.5\n",
    "num_workers = 2\n",
    "batch_size = 1\n",
    "print('best_threshold', best_threshold)\n",
    "min_size = 3500\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "df = pd.read_csv(sample_submission_path)\n",
    "\n",
    "testset = DataLoader(\n",
    "    TestDataset(test_data_folder, df, mean, std,1),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls \"../input/atteffunetcombo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"../input/atteffunetcombo/atteffunetcomboloss1.pth\"\n",
    "device = torch.device(\"cuda\")\n",
    "model = get_efficientunet_b4(out_channels=4, concat_input=True, pretrained=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(state[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"../input/attefbceloss4/atteffunetbceloss2.pth\"\n",
    "device = torch.device(\"cuda\")\n",
    "model2 = get_efficientunet_b4(out_channels=4, concat_input=True, pretrained=False)\n",
    "model2.to(device)\n",
    "model2.eval()\n",
    "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "model2.load_state_dict(state[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"../input/attres182/attres18unetbceloss3.pth\"\n",
    "device = torch.device(\"cuda\")\n",
    "model3 = smp.Unet(\"resnet18\", encoder_weights=None, classes=4, activation=None,attention_type=\"scse\")\n",
    "model3.to(device)\n",
    "model3.eval()\n",
    "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "model3.load_state_dict(state[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"../input/unetstartermodelfile4/model89088.pth\"\n",
    "device = torch.device(\"cuda\")\n",
    "model4 = smp.Unet(\"resnet18\", encoder_weights=None, classes=4, activation=None)\n",
    "model4.to(device)\n",
    "model4.eval()\n",
    "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "model4.load_state_dict(state[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i, batch in enumerate(tqdm(testset)):\n",
    "    fnames, images = batch\n",
    "    \n",
    "    py = (torch.sigmoid(model(images.to(device)))+ (torch.sigmoid(model(images.flip(3).to(device)))).flip(3))/2\n",
    "    batch_preds = 0.2518*py\n",
    "    \n",
    "    py = (torch.sigmoid(model2(images.to(device)))+ (torch.sigmoid(model2(images.flip(3).to(device)))).flip(3))/2\n",
    "    batch_preds += 0.252*py\n",
    "    \n",
    "    py = (torch.sigmoid(model3(images.to(device))) + (torch.sigmoid(model3(images.flip(3).to(device)))).flip(3))/2\n",
    "    batch_preds += 0.249*py\n",
    "    \n",
    "    py = (torch.sigmoid(model4(images.to(device))) + (torch.sigmoid(model4(images.flip(3).to(device)))).flip(3))/2\n",
    "    batch_preds += 0.2472*py\n",
    "    \n",
    "    batch_preds = batch_preds.detach().cpu().numpy()\n",
    "    \n",
    "    j=0\n",
    "    for fname, preds in zip(fnames, batch_preds):\n",
    "        \n",
    "        for cls, pred in enumerate(preds):    \n",
    "            #predict=pred2[cls]\n",
    "            min_size=2000\n",
    "            th=0.55\n",
    "            if cls==0:\n",
    "                min_size=700    \n",
    "            if cls==2:\n",
    "                th=0.65\n",
    "            if cls == 1:\n",
    "                th=0.85\n",
    "            pred=(pred>th).astype(int)\n",
    "            \n",
    "\n",
    "            pred = post_process(pred, 0.45, min_size)\n",
    "            \n",
    "            if pred.sum()>0:\n",
    "                print(cls,pred.sum())\n",
    "                \n",
    "            rle = mask2rle(pred)\n",
    "            name = fname + f\"_{cls+1}\"\n",
    "            predictions.append([name, rle])\n",
    "\n",
    "\n",
    " \n",
    "               \n",
    "df = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])\n",
    "df.to_csv(\"submission.csv\", index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
